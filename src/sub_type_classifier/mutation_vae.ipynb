{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e90610",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netvae'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgripql\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetvae\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'netvae'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gripql\n",
    "from tqdm import tqdm\n",
    "import netvae\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_min_size = 3\n",
    "learning_rate=1e-4\n",
    "batch_size=256\n",
    "epochs=50\n",
    "latent_dim = 768\n",
    "rotation_factor = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b4279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sheet from https://cancer.sanger.ac.uk/cosmic/census?tier=all\n",
    "genesDF = pd.read_csv(\"muta.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c3e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#geneList = genesDF[ (genesDF[\"Somatic\"] == \"yes\") & (genesDF[\"Hallmark\"] == \"Yes\") ].index.to_list()\n",
    "geneList = genesDF[ (genesDF[\"Somatic\"] == \"yes\") ].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53864235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051c0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = gripql.Connection(url='https://bmeg.io/grip', credential_file='../bmeg_credentials.json')\n",
    "G = conn.graph(\"rc6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3256addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "geneMap = dict( (i[0],i[1]) for i in G.query().V().hasLabel(\"Gene\").render([\"gene_id\", \"symbol\"]).execute() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f83265",
   "metadata": {},
   "outputs": [],
   "source": [
    "hugoMap = {}\n",
    "for k,v in geneMap.items():\n",
    "    if v in geneList:\n",
    "        hugoMap[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b825b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = G.query().V('Program:TCGA').out(\"projects\").render(\"$._gid\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17d60042",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetList = list(hugoMap.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84218d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 33/33 [01:19<00:00,  2.42s/it]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for p in tqdm(projects):\n",
    "    q = G.query().V(p).out(\"cases\").out(\"samples\").as_(\"sample\")\n",
    "    q = q.has(gripql.eq(\"$.gdc_attributes.sample_type\", \"Primary Tumor\"))\n",
    "    q = q.out(\"aliquots\").out(\"somatic_callsets\")\n",
    "    q = q.outE().has(gripql.within(\"ensembl_gene\", targetList))\n",
    "    q = q.as_(\"variant\")\n",
    "    q = q.render([\"$sample.submitter_id\", \"$variant.ensembl_gene\"])\n",
    "    for sample, gene in q:\n",
    "        if sample not in data:\n",
    "            data[sample] = {gene:1}\n",
    "        else:\n",
    "            data[sample][gene] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323625c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data).rename(index=geneMap).fillna(0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e330e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KRAS</th>\n",
       "      <th>TET1</th>\n",
       "      <th>CYSLTR2</th>\n",
       "      <th>PML</th>\n",
       "      <th>BRCA2</th>\n",
       "      <th>TP53</th>\n",
       "      <th>PIK3CA</th>\n",
       "      <th>HIST1H4I</th>\n",
       "      <th>CCNC</th>\n",
       "      <th>FBXW7</th>\n",
       "      <th>...</th>\n",
       "      <th>SUB1</th>\n",
       "      <th>ISX</th>\n",
       "      <th>SUFU</th>\n",
       "      <th>EED</th>\n",
       "      <th>NDRG1</th>\n",
       "      <th>FSTL3</th>\n",
       "      <th>FCGR2B</th>\n",
       "      <th>SLC45A3</th>\n",
       "      <th>RMI2</th>\n",
       "      <th>RAP1B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-AG-A00C-01A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-EI-6917-01A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-DY-A0XA-01A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-F5-6810-01A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-AG-A01W-01A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-VQ-A8PD-01A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-MX-A5UJ-01A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-BR-6564-01A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-BR-4191-01A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-BR-6707-01A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9391 rows × 657 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  KRAS  TET1  CYSLTR2  PML  BRCA2  TP53  PIK3CA  HIST1H4I  \\\n",
       "TCGA-AG-A00C-01A   1.0   1.0      1.0  1.0    1.0   1.0     1.0       1.0   \n",
       "TCGA-EI-6917-01A   0.0   1.0      1.0  0.0    0.0   1.0     1.0       0.0   \n",
       "TCGA-DY-A0XA-01A   0.0   0.0      0.0  0.0    0.0   1.0     1.0       0.0   \n",
       "TCGA-F5-6810-01A   0.0   0.0      0.0  0.0    0.0   1.0     0.0       0.0   \n",
       "TCGA-AG-A01W-01A   1.0   0.0      0.0  0.0    0.0   1.0     0.0       0.0   \n",
       "...                ...   ...      ...  ...    ...   ...     ...       ...   \n",
       "TCGA-VQ-A8PD-01A   0.0   0.0      0.0  0.0    0.0   0.0     0.0       0.0   \n",
       "TCGA-MX-A5UJ-01A   0.0   0.0      0.0  0.0    0.0   0.0     0.0       0.0   \n",
       "TCGA-BR-6564-01A   0.0   0.0      0.0  0.0    0.0   0.0     0.0       0.0   \n",
       "TCGA-BR-4191-01A   0.0   0.0      0.0  0.0    0.0   0.0     0.0       0.0   \n",
       "TCGA-BR-6707-01A   0.0   0.0      0.0  0.0    0.0   0.0     1.0       0.0   \n",
       "\n",
       "                  CCNC  FBXW7  ...  SUB1  ISX  SUFU  EED  NDRG1  FSTL3  \\\n",
       "TCGA-AG-A00C-01A   1.0    1.0  ...   0.0  0.0   0.0  0.0    0.0    0.0   \n",
       "TCGA-EI-6917-01A   0.0    1.0  ...   0.0  0.0   0.0  0.0    0.0    0.0   \n",
       "TCGA-DY-A0XA-01A   0.0    0.0  ...   0.0  0.0   0.0  0.0    0.0    0.0   \n",
       "TCGA-F5-6810-01A   0.0    0.0  ...   0.0  0.0   0.0  0.0    0.0    0.0   \n",
       "TCGA-AG-A01W-01A   0.0    0.0  ...   0.0  0.0   0.0  0.0    0.0    0.0   \n",
       "...                ...    ...  ...   ...  ...   ...  ...    ...    ...   \n",
       "TCGA-VQ-A8PD-01A   0.0    0.0  ...   0.0  0.0   0.0  0.0    0.0    0.0   \n",
       "TCGA-MX-A5UJ-01A   0.0    1.0  ...   0.0  0.0   0.0  1.0    0.0    1.0   \n",
       "TCGA-BR-6564-01A   0.0    0.0  ...   0.0  0.0   0.0  0.0    0.0    0.0   \n",
       "TCGA-BR-4191-01A   0.0    0.0  ...   0.0  0.0   0.0  0.0    0.0    0.0   \n",
       "TCGA-BR-6707-01A   0.0    0.0  ...   0.0  0.0   0.0  0.0    0.0    0.0   \n",
       "\n",
       "                  FCGR2B  SLC45A3  RMI2  RAP1B  \n",
       "TCGA-AG-A00C-01A     0.0      0.0   0.0    0.0  \n",
       "TCGA-EI-6917-01A     0.0      0.0   0.0    0.0  \n",
       "TCGA-DY-A0XA-01A     0.0      0.0   0.0    0.0  \n",
       "TCGA-F5-6810-01A     0.0      0.0   0.0    0.0  \n",
       "TCGA-AG-A01W-01A     0.0      0.0   0.0    0.0  \n",
       "...                  ...      ...   ...    ...  \n",
       "TCGA-VQ-A8PD-01A     0.0      0.0   0.0    0.0  \n",
       "TCGA-MX-A5UJ-01A     0.0      0.0   0.0    0.0  \n",
       "TCGA-BR-6564-01A     0.0      0.0   0.0    0.0  \n",
       "TCGA-BR-4191-01A     0.0      0.0   0.0    0.0  \n",
       "TCGA-BR-6707-01A     0.0      0.0   0.0    0.0  \n",
       "\n",
       "[9391 rows x 657 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb6ea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 13:27:36.455992: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-08-01 13:27:36.456023: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-08-01 13:27:36.456032: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2024-08-01 13:27:36.456069: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-01 13:27:36.456084: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 657)]                0         []                            \n",
      "                                                                                                  \n",
      " pathway_layer (Dense)       (None, 768)                  505344    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batchnorm (BatchNormalizat  (None, 768)                  3072      ['pathway_layer[0][0]']       \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " z_mean (Dense)              (None, 768)                  590592    ['batchnorm[0][0]']           \n",
      "                                                                                                  \n",
      " z_log_var (Dense)           (None, 768)                  590592    ['batchnorm[0][0]']           \n",
      "                                                                                                  \n",
      " sampling (Sampling)         (None, 768)                  0         ['z_mean[0][0]',              \n",
      "                                                                     'z_log_var[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1689600 (6.45 MB)\n",
      "Trainable params: 1688064 (6.44 MB)\n",
      "Non-trainable params: 1536 (6.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 768)]             0         \n",
      "                                                                 \n",
      " decoder_input (Dense)       (None, 657)               505233    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505233 (1.93 MB)\n",
      "Trainable params: 505233 (1.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 13:27:37.159445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 31ms/step - loss: 530.3608 - reconstruction_loss: 496.3244 - kl_loss: 13.5592\n",
      "Epoch 2/250\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 412.7623 - reconstruction_loss: 339.6320 - kl_loss: 28.1311\n",
      "Epoch 3/250\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 239.8156 - reconstruction_loss: 163.9230 - kl_loss: 53.9169\n",
      "Epoch 4/250\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 169.0732 - reconstruction_loss: 110.5033 - kl_loss: 50.2876\n",
      "Epoch 5/250\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 138.4125 - reconstruction_loss: 90.5012 - kl_loss: 44.2071\n",
      "Epoch 6/250\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 121.7434 - reconstruction_loss: 80.2751 - kl_loss: 39.5041\n",
      "Epoch 7/250\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 113.1303 - reconstruction_loss: 74.7335 - kl_loss: 35.8925\n",
      "Epoch 8/250\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 105.2206 - reconstruction_loss: 70.8489 - kl_loss: 33.1545\n",
      "Epoch 9/250\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 99.8236 - reconstruction_loss: 68.4200 - kl_loss: 30.7206\n",
      "Epoch 10/250\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 95.7634 - reconstruction_loss: 66.3744 - kl_loss: 28.9788\n",
      "Epoch 11/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 92.9814 - reconstruction_loss: 65.0757 - kl_loss: 27.2958\n",
      "Epoch 12/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 91.3372 - reconstruction_loss: 64.1432 - kl_loss: 25.7534\n",
      "Epoch 13/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 88.7364 - reconstruction_loss: 63.1839 - kl_loss: 24.5373\n",
      "Epoch 14/250\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86.0943 - reconstruction_loss: 62.5923 - kl_loss: 23.3509\n",
      "Epoch 15/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 84.8478 - reconstruction_loss: 62.1584 - kl_loss: 22.3088\n",
      "Epoch 16/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 83.2307 - reconstruction_loss: 61.3195 - kl_loss: 21.4347\n",
      "Epoch 17/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 82.6850 - reconstruction_loss: 60.9226 - kl_loss: 20.5045\n",
      "Epoch 18/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 79.6660 - reconstruction_loss: 60.0496 - kl_loss: 19.9227\n",
      "Epoch 19/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 79.5126 - reconstruction_loss: 59.6114 - kl_loss: 19.1427\n",
      "Epoch 20/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 79.3856 - reconstruction_loss: 61.4756 - kl_loss: 18.5337\n",
      "Epoch 21/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 77.9816 - reconstruction_loss: 59.6735 - kl_loss: 17.7523\n",
      "Epoch 22/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 76.1832 - reconstruction_loss: 58.2606 - kl_loss: 17.4553\n",
      "Epoch 23/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 77.0855 - reconstruction_loss: 59.8451 - kl_loss: 16.8453\n",
      "Epoch 24/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 75.0896 - reconstruction_loss: 58.3116 - kl_loss: 16.3714\n",
      "Epoch 25/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 73.7617 - reconstruction_loss: 57.6430 - kl_loss: 15.9931\n",
      "Epoch 26/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 73.0214 - reconstruction_loss: 57.2272 - kl_loss: 15.5563\n",
      "Epoch 27/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 73.2508 - reconstruction_loss: 56.8250 - kl_loss: 15.2158\n",
      "Epoch 28/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 71.1679 - reconstruction_loss: 56.6844 - kl_loss: 14.8002\n",
      "Epoch 29/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 71.4765 - reconstruction_loss: 56.2931 - kl_loss: 14.5311\n",
      "Epoch 30/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 70.2697 - reconstruction_loss: 56.1145 - kl_loss: 14.1747\n",
      "Epoch 31/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 68.8658 - reconstruction_loss: 55.6522 - kl_loss: 13.8354\n",
      "Epoch 32/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 68.6908 - reconstruction_loss: 54.9928 - kl_loss: 13.6228\n",
      "Epoch 33/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 68.3406 - reconstruction_loss: 54.8343 - kl_loss: 13.3308\n",
      "Epoch 34/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 69.0036 - reconstruction_loss: 54.8296 - kl_loss: 13.0068\n",
      "Epoch 35/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 67.7890 - reconstruction_loss: 54.5883 - kl_loss: 12.8023\n",
      "Epoch 36/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 66.7190 - reconstruction_loss: 54.5131 - kl_loss: 12.5811\n",
      "Epoch 37/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 66.3477 - reconstruction_loss: 54.2390 - kl_loss: 12.2991\n",
      "Epoch 38/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 65.9959 - reconstruction_loss: 54.2291 - kl_loss: 12.1017\n",
      "Epoch 39/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 65.2764 - reconstruction_loss: 53.6692 - kl_loss: 11.9263\n",
      "Epoch 40/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 65.1424 - reconstruction_loss: 53.5007 - kl_loss: 11.7202\n",
      "Epoch 41/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 64.3110 - reconstruction_loss: 53.1703 - kl_loss: 11.5092\n",
      "Epoch 42/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 65.5753 - reconstruction_loss: 53.6092 - kl_loss: 11.3442\n",
      "Epoch 43/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 65.4299 - reconstruction_loss: 53.4257 - kl_loss: 11.1449\n",
      "Epoch 44/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 63.8899 - reconstruction_loss: 52.6998 - kl_loss: 10.9901\n",
      "Epoch 45/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 64.3195 - reconstruction_loss: 52.9415 - kl_loss: 10.8240\n",
      "Epoch 46/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 63.4702 - reconstruction_loss: 52.4300 - kl_loss: 10.7402\n",
      "Epoch 47/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 63.5966 - reconstruction_loss: 52.0676 - kl_loss: 10.5494\n",
      "Epoch 48/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 62.3028 - reconstruction_loss: 51.9113 - kl_loss: 10.4270\n",
      "Epoch 49/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 62.5151 - reconstruction_loss: 52.1132 - kl_loss: 10.3031\n",
      "Epoch 50/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 62.8135 - reconstruction_loss: 51.7988 - kl_loss: 10.1286\n",
      "Epoch 51/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 61.6957 - reconstruction_loss: 51.6618 - kl_loss: 10.0481\n",
      "Epoch 52/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 61.0387 - reconstruction_loss: 51.4517 - kl_loss: 9.9224\n",
      "Epoch 53/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 62.7354 - reconstruction_loss: 51.8328 - kl_loss: 9.8313\n",
      "Epoch 54/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 62.9794 - reconstruction_loss: 52.0919 - kl_loss: 9.6825\n",
      "Epoch 55/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 60.8485 - reconstruction_loss: 51.4635 - kl_loss: 9.5497\n",
      "Epoch 56/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 60.1232 - reconstruction_loss: 50.9173 - kl_loss: 9.5324\n",
      "Epoch 57/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 59.9804 - reconstruction_loss: 50.8569 - kl_loss: 9.3681\n",
      "Epoch 58/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 60.7750 - reconstruction_loss: 50.8139 - kl_loss: 9.3221\n",
      "Epoch 59/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 60.2363 - reconstruction_loss: 50.6610 - kl_loss: 9.2400\n",
      "Epoch 60/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 58.9478 - reconstruction_loss: 50.5511 - kl_loss: 9.1509\n",
      "Epoch 61/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 58.7062 - reconstruction_loss: 50.2875 - kl_loss: 9.0309\n",
      "Epoch 62/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 59.0957 - reconstruction_loss: 49.8286 - kl_loss: 8.9758\n",
      "Epoch 63/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 59.1922 - reconstruction_loss: 49.7794 - kl_loss: 8.9147\n",
      "Epoch 64/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 58.2705 - reconstruction_loss: 49.4275 - kl_loss: 8.8550\n",
      "Epoch 65/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 58.5650 - reconstruction_loss: 49.3278 - kl_loss: 8.8150\n",
      "Epoch 66/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 58.4589 - reconstruction_loss: 49.4200 - kl_loss: 8.7019\n",
      "Epoch 67/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 58.8602 - reconstruction_loss: 49.0845 - kl_loss: 8.6683\n",
      "Epoch 68/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 56.3587 - reconstruction_loss: 48.8921 - kl_loss: 8.6048\n",
      "Epoch 69/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 56.2600 - reconstruction_loss: 48.7667 - kl_loss: 8.5460\n",
      "Epoch 70/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 57.5090 - reconstruction_loss: 48.7055 - kl_loss: 8.4842\n",
      "Epoch 71/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 56.1795 - reconstruction_loss: 48.5415 - kl_loss: 8.4215\n",
      "Epoch 72/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 56.6181 - reconstruction_loss: 48.3148 - kl_loss: 8.3931\n",
      "Epoch 73/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 55.9637 - reconstruction_loss: 48.2388 - kl_loss: 8.3229\n",
      "Epoch 74/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 56.0250 - reconstruction_loss: 48.1648 - kl_loss: 8.2916\n",
      "Epoch 75/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 55.7182 - reconstruction_loss: 48.3245 - kl_loss: 8.2226\n",
      "Epoch 76/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 56.7706 - reconstruction_loss: 48.8807 - kl_loss: 8.1768\n",
      "Epoch 77/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 57.3561 - reconstruction_loss: 48.8161 - kl_loss: 8.0558\n",
      "Epoch 78/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 55.7721 - reconstruction_loss: 47.7309 - kl_loss: 8.1316\n",
      "Epoch 79/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 56.0948 - reconstruction_loss: 47.3530 - kl_loss: 8.0871\n",
      "Epoch 80/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 55.3618 - reconstruction_loss: 47.2913 - kl_loss: 8.0600\n",
      "Epoch 81/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 55.5421 - reconstruction_loss: 47.0632 - kl_loss: 8.0118\n",
      "Epoch 82/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 54.9706 - reconstruction_loss: 47.0161 - kl_loss: 8.0058\n",
      "Epoch 83/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 54.8108 - reconstruction_loss: 46.9075 - kl_loss: 7.9630\n",
      "Epoch 84/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 54.4228 - reconstruction_loss: 47.1220 - kl_loss: 7.9302\n",
      "Epoch 85/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 54.2292 - reconstruction_loss: 46.8027 - kl_loss: 7.8691\n",
      "Epoch 86/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 54.8451 - reconstruction_loss: 46.5071 - kl_loss: 7.9018\n",
      "Epoch 87/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 54.6727 - reconstruction_loss: 46.2784 - kl_loss: 7.8680\n",
      "Epoch 88/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 53.7943 - reconstruction_loss: 46.2355 - kl_loss: 7.8278\n",
      "Epoch 89/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 53.9787 - reconstruction_loss: 46.0626 - kl_loss: 7.8092\n",
      "Epoch 90/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 53.2475 - reconstruction_loss: 46.0385 - kl_loss: 7.7860\n",
      "Epoch 91/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 54.1187 - reconstruction_loss: 46.2731 - kl_loss: 7.7626\n",
      "Epoch 92/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 53.1623 - reconstruction_loss: 45.9870 - kl_loss: 7.7292\n",
      "Epoch 93/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 54.2169 - reconstruction_loss: 45.8435 - kl_loss: 7.7123\n",
      "Epoch 94/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 53.5931 - reconstruction_loss: 45.4996 - kl_loss: 7.7619\n",
      "Epoch 95/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 52.4063 - reconstruction_loss: 45.3684 - kl_loss: 7.7303\n",
      "Epoch 96/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 53.1191 - reconstruction_loss: 45.1966 - kl_loss: 7.7041\n",
      "Epoch 97/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 53.6237 - reconstruction_loss: 45.3163 - kl_loss: 7.7005\n",
      "Epoch 98/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 52.7590 - reconstruction_loss: 44.9618 - kl_loss: 7.6949\n",
      "Epoch 99/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 52.0638 - reconstruction_loss: 44.8075 - kl_loss: 7.7135\n",
      "Epoch 100/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 52.6427 - reconstruction_loss: 44.7347 - kl_loss: 7.6498\n",
      "Epoch 101/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 52.6934 - reconstruction_loss: 44.4999 - kl_loss: 7.6806\n",
      "Epoch 102/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 51.7377 - reconstruction_loss: 44.3234 - kl_loss: 7.6792\n",
      "Epoch 103/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 51.5599 - reconstruction_loss: 44.1827 - kl_loss: 7.6738\n",
      "Epoch 104/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 52.1019 - reconstruction_loss: 44.0022 - kl_loss: 7.6780\n",
      "Epoch 105/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 51.3203 - reconstruction_loss: 43.9460 - kl_loss: 7.6628\n",
      "Epoch 106/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 52.2089 - reconstruction_loss: 43.8221 - kl_loss: 7.6559\n",
      "Epoch 107/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 51.4781 - reconstruction_loss: 43.6441 - kl_loss: 7.6827\n",
      "Epoch 108/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 50.9801 - reconstruction_loss: 43.6381 - kl_loss: 7.6682\n",
      "Epoch 109/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 51.2182 - reconstruction_loss: 43.8570 - kl_loss: 7.6399\n",
      "Epoch 110/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 50.5648 - reconstruction_loss: 43.3778 - kl_loss: 7.6650\n",
      "Epoch 111/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 49.7848 - reconstruction_loss: 43.1503 - kl_loss: 7.6908\n",
      "Epoch 112/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 50.6719 - reconstruction_loss: 43.0310 - kl_loss: 7.6672\n",
      "Epoch 113/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 50.7763 - reconstruction_loss: 42.7958 - kl_loss: 7.6932\n",
      "Epoch 114/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 51.1222 - reconstruction_loss: 42.8405 - kl_loss: 7.7010\n",
      "Epoch 115/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 50.5714 - reconstruction_loss: 42.6716 - kl_loss: 7.6875\n",
      "Epoch 116/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 49.5227 - reconstruction_loss: 42.4449 - kl_loss: 7.7011\n",
      "Epoch 117/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 49.9253 - reconstruction_loss: 42.2456 - kl_loss: 7.7261\n",
      "Epoch 118/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 49.6681 - reconstruction_loss: 42.2148 - kl_loss: 7.7248\n",
      "Epoch 119/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 51.1092 - reconstruction_loss: 42.0765 - kl_loss: 7.7355\n",
      "Epoch 120/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 50.3668 - reconstruction_loss: 41.8669 - kl_loss: 7.7393\n",
      "Epoch 121/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 49.3288 - reconstruction_loss: 41.8027 - kl_loss: 7.7671\n",
      "Epoch 122/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 49.6931 - reconstruction_loss: 41.7987 - kl_loss: 7.7462\n",
      "Epoch 123/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 48.7748 - reconstruction_loss: 41.6852 - kl_loss: 7.7852\n",
      "Epoch 124/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 48.8646 - reconstruction_loss: 41.4873 - kl_loss: 7.7906\n",
      "Epoch 125/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 9ms/step - loss: 49.7648 - reconstruction_loss: 41.2386 - kl_loss: 7.8154\n",
      "Epoch 126/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 48.9892 - reconstruction_loss: 41.1166 - kl_loss: 7.8158\n",
      "Epoch 127/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 49.2155 - reconstruction_loss: 40.8949 - kl_loss: 7.8488\n",
      "Epoch 128/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 48.4930 - reconstruction_loss: 40.8605 - kl_loss: 7.8382\n",
      "Epoch 129/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 48.0069 - reconstruction_loss: 40.7456 - kl_loss: 7.8715\n",
      "Epoch 130/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 47.7505 - reconstruction_loss: 40.6151 - kl_loss: 7.8807\n",
      "Epoch 131/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 49.1838 - reconstruction_loss: 40.4392 - kl_loss: 7.8879\n",
      "Epoch 132/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 49.4178 - reconstruction_loss: 40.2438 - kl_loss: 7.9274\n",
      "Epoch 133/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 47.4915 - reconstruction_loss: 40.0776 - kl_loss: 7.9324\n",
      "Epoch 134/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 47.5136 - reconstruction_loss: 39.9166 - kl_loss: 7.9653\n",
      "Epoch 135/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 48.0030 - reconstruction_loss: 39.7829 - kl_loss: 7.9737\n",
      "Epoch 136/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 48.0261 - reconstruction_loss: 39.6858 - kl_loss: 7.9906\n",
      "Epoch 137/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 48.1209 - reconstruction_loss: 39.4467 - kl_loss: 8.0162\n",
      "Epoch 138/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 47.4663 - reconstruction_loss: 39.2946 - kl_loss: 8.0258\n",
      "Epoch 139/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 47.8073 - reconstruction_loss: 39.3057 - kl_loss: 8.0492\n",
      "Epoch 140/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 46.5619 - reconstruction_loss: 39.1357 - kl_loss: 8.0858\n",
      "Epoch 141/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 47.1480 - reconstruction_loss: 38.9134 - kl_loss: 8.0864\n",
      "Epoch 142/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 47.8274 - reconstruction_loss: 38.7324 - kl_loss: 8.1156\n",
      "Epoch 143/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 46.6449 - reconstruction_loss: 38.6106 - kl_loss: 8.1457\n",
      "Epoch 144/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 46.2729 - reconstruction_loss: 38.4504 - kl_loss: 8.1602\n",
      "Epoch 145/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 46.7106 - reconstruction_loss: 38.2935 - kl_loss: 8.1913\n",
      "Epoch 146/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 46.2635 - reconstruction_loss: 38.2238 - kl_loss: 8.1995\n",
      "Epoch 147/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 46.4525 - reconstruction_loss: 38.0809 - kl_loss: 8.2324\n",
      "Epoch 148/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 45.8543 - reconstruction_loss: 37.9263 - kl_loss: 8.2592\n",
      "Epoch 149/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 45.4177 - reconstruction_loss: 37.7960 - kl_loss: 8.2679\n",
      "Epoch 150/250\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 45.9904 - reconstruction_loss: 37.7093 - kl_loss: 8.3002\n",
      "Epoch 151/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 45.7150 - reconstruction_loss: 37.5166 - kl_loss: 8.3133\n",
      "Epoch 152/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 45.7740 - reconstruction_loss: 37.3311 - kl_loss: 8.3491\n",
      "Epoch 153/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 45.4722 - reconstruction_loss: 37.2155 - kl_loss: 8.3673\n",
      "Epoch 154/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 44.6149 - reconstruction_loss: 37.0465 - kl_loss: 8.4015\n",
      "Epoch 155/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 45.5500 - reconstruction_loss: 36.9052 - kl_loss: 8.4154\n",
      "Epoch 156/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 45.4924 - reconstruction_loss: 36.7700 - kl_loss: 8.4516\n",
      "Epoch 157/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 44.7365 - reconstruction_loss: 36.6064 - kl_loss: 8.4763\n",
      "Epoch 158/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 45.0723 - reconstruction_loss: 36.4632 - kl_loss: 8.4987\n",
      "Epoch 159/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 45.0679 - reconstruction_loss: 36.4509 - kl_loss: 8.5078\n",
      "Epoch 160/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 44.2620 - reconstruction_loss: 36.3436 - kl_loss: 8.5433\n",
      "Epoch 161/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 45.3612 - reconstruction_loss: 36.2111 - kl_loss: 8.5737\n",
      "Epoch 162/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 45.3032 - reconstruction_loss: 35.9630 - kl_loss: 8.5962\n",
      "Epoch 163/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 44.4739 - reconstruction_loss: 35.8197 - kl_loss: 8.6264\n",
      "Epoch 164/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 44.3238 - reconstruction_loss: 35.5903 - kl_loss: 8.6506\n",
      "Epoch 165/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 44.6407 - reconstruction_loss: 35.4534 - kl_loss: 8.6846\n",
      "Epoch 166/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 43.6753 - reconstruction_loss: 35.3037 - kl_loss: 8.7033\n",
      "Epoch 167/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 43.9373 - reconstruction_loss: 35.1652 - kl_loss: 8.7233\n",
      "Epoch 168/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 43.6007 - reconstruction_loss: 34.9950 - kl_loss: 8.7615\n",
      "Epoch 169/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 43.2217 - reconstruction_loss: 34.8799 - kl_loss: 8.7853\n",
      "Epoch 170/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 43.8853 - reconstruction_loss: 34.7665 - kl_loss: 8.8036\n",
      "Epoch 171/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 43.0068 - reconstruction_loss: 34.6292 - kl_loss: 8.8245\n",
      "Epoch 172/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 42.8718 - reconstruction_loss: 34.5045 - kl_loss: 8.8595\n",
      "Epoch 173/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 42.4136 - reconstruction_loss: 34.3362 - kl_loss: 8.8930\n",
      "Epoch 174/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 42.6873 - reconstruction_loss: 34.2115 - kl_loss: 8.9196\n",
      "Epoch 175/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 43.3426 - reconstruction_loss: 34.0443 - kl_loss: 8.9365\n",
      "Epoch 176/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 43.5194 - reconstruction_loss: 33.9599 - kl_loss: 8.9545\n",
      "Epoch 177/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 43.1407 - reconstruction_loss: 33.8117 - kl_loss: 8.9863\n",
      "Epoch 178/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 42.6200 - reconstruction_loss: 33.6342 - kl_loss: 9.0109\n",
      "Epoch 179/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 42.7488 - reconstruction_loss: 33.5457 - kl_loss: 9.0388\n",
      "Epoch 180/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 42.0815 - reconstruction_loss: 33.4336 - kl_loss: 9.0638\n",
      "Epoch 181/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 42.5050 - reconstruction_loss: 33.2762 - kl_loss: 9.0972\n",
      "Epoch 182/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 42.4716 - reconstruction_loss: 33.1818 - kl_loss: 9.1073\n",
      "Epoch 183/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 42.3992 - reconstruction_loss: 33.0124 - kl_loss: 9.1404\n",
      "Epoch 184/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 42.1647 - reconstruction_loss: 32.8040 - kl_loss: 9.1691\n",
      "Epoch 185/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 41.9797 - reconstruction_loss: 32.6887 - kl_loss: 9.1961\n",
      "Epoch 186/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 41.9323 - reconstruction_loss: 32.5788 - kl_loss: 9.2193\n",
      "Epoch 187/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 9ms/step - loss: 41.8149 - reconstruction_loss: 32.4385 - kl_loss: 9.2384\n",
      "Epoch 188/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 41.8481 - reconstruction_loss: 32.3276 - kl_loss: 9.2668\n",
      "Epoch 189/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 41.5610 - reconstruction_loss: 32.1645 - kl_loss: 9.2868\n",
      "Epoch 190/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 41.4276 - reconstruction_loss: 32.0202 - kl_loss: 9.3152\n",
      "Epoch 191/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 41.9995 - reconstruction_loss: 31.9406 - kl_loss: 9.3450\n",
      "Epoch 192/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 41.7185 - reconstruction_loss: 31.8352 - kl_loss: 9.3531\n",
      "Epoch 193/250\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 41.0655 - reconstruction_loss: 31.7095 - kl_loss: 9.3927\n",
      "Epoch 194/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 41.4423 - reconstruction_loss: 31.5048 - kl_loss: 9.4264\n",
      "Epoch 195/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 41.0659 - reconstruction_loss: 31.3611 - kl_loss: 9.4217\n",
      "Epoch 196/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 40.4762 - reconstruction_loss: 31.1920 - kl_loss: 9.4525\n",
      "Epoch 197/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 40.9490 - reconstruction_loss: 31.0416 - kl_loss: 9.4801\n",
      "Epoch 198/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 41.0205 - reconstruction_loss: 30.9761 - kl_loss: 9.4952\n",
      "Epoch 199/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 40.4183 - reconstruction_loss: 30.8835 - kl_loss: 9.5228\n",
      "Epoch 200/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 40.4140 - reconstruction_loss: 30.7031 - kl_loss: 9.5517\n",
      "Epoch 201/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 40.3765 - reconstruction_loss: 30.5576 - kl_loss: 9.5514\n",
      "Epoch 202/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 40.7550 - reconstruction_loss: 30.4838 - kl_loss: 9.5880\n",
      "Epoch 203/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 40.1227 - reconstruction_loss: 30.3226 - kl_loss: 9.6055\n",
      "Epoch 204/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 40.1834 - reconstruction_loss: 30.1550 - kl_loss: 9.6336\n",
      "Epoch 205/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 39.3822 - reconstruction_loss: 30.0480 - kl_loss: 9.6458\n",
      "Epoch 206/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 39.8160 - reconstruction_loss: 29.9270 - kl_loss: 9.6717\n",
      "Epoch 207/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 39.7442 - reconstruction_loss: 29.7618 - kl_loss: 9.6947\n",
      "Epoch 208/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.8560 - reconstruction_loss: 29.6216 - kl_loss: 9.7063\n",
      "Epoch 209/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.7664 - reconstruction_loss: 29.4997 - kl_loss: 9.7324\n",
      "Epoch 210/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 39.1540 - reconstruction_loss: 29.4170 - kl_loss: 9.7522\n",
      "Epoch 211/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 39.7791 - reconstruction_loss: 29.2982 - kl_loss: 9.7683\n",
      "Epoch 212/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.8724 - reconstruction_loss: 29.2039 - kl_loss: 9.7903\n",
      "Epoch 213/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.5483 - reconstruction_loss: 29.0311 - kl_loss: 9.8141\n",
      "Epoch 214/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.2473 - reconstruction_loss: 28.9125 - kl_loss: 9.8314\n",
      "Epoch 215/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.3302 - reconstruction_loss: 28.8028 - kl_loss: 9.8512\n",
      "Epoch 216/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.7176 - reconstruction_loss: 28.7311 - kl_loss: 9.8660\n",
      "Epoch 217/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.1697 - reconstruction_loss: 28.5439 - kl_loss: 9.8869\n",
      "Epoch 218/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.9812 - reconstruction_loss: 28.4519 - kl_loss: 9.9116\n",
      "Epoch 219/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.6255 - reconstruction_loss: 28.3078 - kl_loss: 9.9305\n",
      "Epoch 220/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.0089 - reconstruction_loss: 28.2594 - kl_loss: 9.9425\n",
      "Epoch 221/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.6142 - reconstruction_loss: 28.1233 - kl_loss: 9.9686\n",
      "Epoch 222/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.7339 - reconstruction_loss: 27.9379 - kl_loss: 9.9780\n",
      "Epoch 223/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 38.6633 - reconstruction_loss: 27.8365 - kl_loss: 9.9972\n",
      "Epoch 224/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.7993 - reconstruction_loss: 27.7122 - kl_loss: 10.0161\n",
      "Epoch 225/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.3802 - reconstruction_loss: 27.5804 - kl_loss: 10.0334\n",
      "Epoch 226/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.7139 - reconstruction_loss: 27.4631 - kl_loss: 10.0399\n",
      "Epoch 227/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.7358 - reconstruction_loss: 27.3684 - kl_loss: 10.0598\n",
      "Epoch 228/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.6163 - reconstruction_loss: 27.3301 - kl_loss: 10.0890\n",
      "Epoch 229/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.9360 - reconstruction_loss: 27.1749 - kl_loss: 10.1039\n",
      "Epoch 230/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.3175 - reconstruction_loss: 26.9836 - kl_loss: 10.1148\n",
      "Epoch 231/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.4815 - reconstruction_loss: 26.8418 - kl_loss: 10.1276\n",
      "Epoch 232/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.2481 - reconstruction_loss: 26.8553 - kl_loss: 10.1385\n",
      "Epoch 233/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 37.0536 - reconstruction_loss: 26.7099 - kl_loss: 10.1626\n",
      "Epoch 234/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 36.3083 - reconstruction_loss: 26.5879 - kl_loss: 10.1760\n",
      "Epoch 235/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 36.5762 - reconstruction_loss: 26.4782 - kl_loss: 10.1848\n",
      "Epoch 236/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 35.8536 - reconstruction_loss: 26.3972 - kl_loss: 10.2069\n",
      "Epoch 237/250\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 37.1772 - reconstruction_loss: 26.3611 - kl_loss: 10.2145\n",
      "Epoch 238/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 36.6096 - reconstruction_loss: 26.1513 - kl_loss: 10.2368\n",
      "Epoch 239/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 36.6246 - reconstruction_loss: 26.0078 - kl_loss: 10.2381\n",
      "Epoch 240/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 35.7983 - reconstruction_loss: 25.8875 - kl_loss: 10.2617\n",
      "Epoch 241/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 36.2298 - reconstruction_loss: 25.8062 - kl_loss: 10.2678\n",
      "Epoch 242/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 36.1757 - reconstruction_loss: 25.6784 - kl_loss: 10.2815\n",
      "Epoch 243/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 35.3396 - reconstruction_loss: 25.5633 - kl_loss: 10.2982\n",
      "Epoch 244/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 36.0914 - reconstruction_loss: 25.4567 - kl_loss: 10.2982\n",
      "Epoch 245/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 35.9308 - reconstruction_loss: 25.3406 - kl_loss: 10.3109\n",
      "Epoch 246/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 36.0007 - reconstruction_loss: 25.2229 - kl_loss: 10.3294\n",
      "Epoch 247/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 35.5362 - reconstruction_loss: 25.1565 - kl_loss: 10.3375\n",
      "Epoch 248/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 35.4847 - reconstruction_loss: 25.0338 - kl_loss: 10.3547\n",
      "Epoch 249/250\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 35.1148 - reconstruction_loss: 24.8919 - kl_loss: 10.3631\n",
      "Epoch 250/250\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 34.7547 - reconstruction_loss: 24.7560 - kl_loss: 10.3694\n"
     ]
    }
   ],
   "source": [
    "epochs=250\n",
    "\n",
    "\n",
    "X_encoder = netvae.build_encoder(X.shape[1], latent_dim)\n",
    "X_decoder = netvae.build_decoder(X.shape[1], latent_dim)\n",
    "X_vae = netvae.VAE(X_encoder, X_decoder)\n",
    "X_vae.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "history = X_vae.fit(X, epochs=epochs, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d749a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25/294 [=>............................] - ETA: 0s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 13:29:03.362635: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 2s 6ms/step\n",
      " 93/294 [========>.....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 13:29:05.696917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "X_pred = pd.DataFrame( X_vae.decoder.predict( X_vae.encoder.predict(X)[0] ), index=X.index, columns=X.columns ).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc00e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939117199391172"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=8\n",
    "sum(X.iloc[i] == X_pred.iloc[i]) / X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb7a58d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9391, 657)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1fa54d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01791587, -0.0791906 ,  0.18129964, ..., -0.08360282,\n",
       "         0.14226487,  0.19072601],\n",
       "       [ 0.06319378, -0.16567634, -0.78152347, ...,  0.16215864,\n",
       "        -1.0181475 , -0.01571302],\n",
       "       [ 0.1189163 , -0.00389188,  0.04327488, ..., -0.19779831,\n",
       "        -0.10879896,  0.0977457 ],\n",
       "       ...,\n",
       "       [-0.13054757,  0.11437189,  0.08394529, ..., -0.2223345 ,\n",
       "        -0.14266002, -0.03218059],\n",
       "       [ 0.1231217 ,  0.10812236,  0.16982532, ..., -0.06853131,\n",
       "        -0.15471339,  0.02864742],\n",
       "       [ 0.06914293, -0.05472783,  0.25650588, ..., -0.01729879,\n",
       "        -0.05574045,  0.03449553]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vae.encoder.predict(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761efb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
